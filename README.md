# Meta AR Development

### Introduction
This document is a guide to the development of AR. It is intended to be a living document, and will be updated as the project progresses.   

**Table of Contents**

### Introduction to AR Development or Augmented Reality Development
AR development is the creation of augmented reality applications. Augmented reality is the integration of digital information with the user's environment in real time. Unlike virtual reality, which creates a totally artificial environment, augmented reality uses the existing environment and overlays new information on top of it, it's like adding a digital layer to the real world around you, and it's superimposed in real time.

#### XR Spectrum or Extended Reality Spectrum
The XR spectrum is a way of categorizing the different types of reality technologies. It is a spectrum that goes from the real world to the virtual world. The real world is on the left side of the spectrum, and the virtual world is on the right side of the spectrum.

#### AR or Augmented Reality
AR is the oldes member of the XR family. It is the baseline of the XR spectrum, it is approachable, accessible and the eviroment is the real world.

#### AV or Aumented Virtuality
The AV enviroment is digital and the objects are real, brinding real-life content into the virtual space.

#### MR or Mixed Reality
MR is a technology that allows you to create a blend of the physical and digital world.

#### VR or Virtual Reality
VR is in the top end of the spectrum, this technollogy offers a fully inmersive experience, the user will be trully engaged and absorbed in the virtual world.

### The XR spectrum resources

![XR Spectrum](/img/XR.png)

#### Computer Vision
Computer vision is a field of artificial intelligence that trains computers to interpret and understand the visual world. Using digital images from cameras and videos and deep learning models, machines can accurately identify and classify objects — and then react to what they “see.”

#### Computer Vision categories
Computers vision helps computers to "See" and algorithms are used to identify and process images. There are different categories of computer vision, and each one has a different purpose.

### Object Detection
Object detection is a computer vision technique that allows us to identify and locate objects in an image or video. With this kind of identification and localization, object detection can be used to count objects in a scene and determine and track their precise locations, all while accurately labeling them.

### Segmentation
Image segmentation is the process of partitioning an image into multiple segments. The goal of segmentation is to simplify and/or change the representation of an image into something that is more meaningful and easier to analyze.

### Instance Segmentation
Instance segmentation is one step ahead of semantic segmentation. It is the process of identifying each distinct object of interest in the image and assign them a class label. It is used to identify the location of each object in an image and also classify each pixel of an image to its corresponding class.

### 2D Tracking
2D Tracking is use to identify positions and pixels of the same object over and over again, and with this unique identifiers are going to be created. Then, it tracks the objects as they move around the frame.

### 3D Tracking
In this category a set of defining anchor points and coordinates or facial landmarks are identified around the eyes, eyebrows, nose, mouth, and jaw line. This data can be used to precisely overlay 3D content, like an AR mask or an AR hat on top of your face.

### Human Pose Estimation task
Human pose estimation is the task of estimating the configuration of the human body (pose) from a single image or a video. It is a key component in understanding the visual world and a core problem for several applications such as human-computer interaction, augmented reality, and robotics.

### World Tracking
World tracking is the process that provides a real-time estimate of how the divice is moving relative to the enviroment.

#### SDLC or Software Development Life Cycle
The software development life cycle (SDLC) is a framework defining tasks performed at each step in the software development process. SDLC is a structure followed by a development team within the software organization. It consists of a detailed plan describing how to develop, maintain, replace and alter or enhance specific software. The life cycle defines a methodology for improving the quality of software and the overall development process.

### Machine learning in computer vision
Machine learning is a field of artificial intelligence (AI) that gives computers the ability to learn without being explicitly programmed. In the past decade, machine learning has given us self-driving cars, practical speech recognition, effective web search, and a vastly improved understanding of the human genome.

![Machine Learning](/img/computer_vision.png)

#### Image Processing (neural networks)
Image processing is a method to perform some operations on an image, in order to get an enhanced image or to extract some useful information from it. It is a type of signal processing in which input is an image and output may be image or characteristics/features associated with that image.

### Spatial mapping, anchoring and shaders
Spatial mapping is the process of creating a 3D map of the environment around the device. This is done by using the camera and sensors on the device to detect the size and shape of the environment. The device then uses this information to create a 3D map of the environment.

#### Spatial mapping and anchoring
It is the process of creating a 3D map of the environment around the device. This is done by using the camera and sensors on the device to detect the size and shape of the environment. The device then uses this information to create a 3D map of the environment. This map is then used to create a virtual environment that is overlaid on top of the real world.

#### SLAM or Simultaneous Localization and Mapping
SLAM is a technology that allows a device to map its environment while positioning itself in it. It is the process by which a mobile robot can build a map of an environment and at the same time use this map to determine its location.

#### Shaders
Shaders are small programs that run on the GPU. They are used to calculate the color of each pixel on the screen. Shaders are used to create effects like shadows, reflections, and lighting.

#### SDLC or Software Development Life Cycle
The software development life cycle (SDLC) is a framework defining tasks performed at each step in the software development process. SDLC is a structure followed by a development team within the software organization. It consists of a detailed plan describing how to develop, maintain, replace and alter or enhance specific software. The life cycle defines a methodology for improving the quality of software and the overall development process.

#### SDLC Core Phases
- **Planning** 
- **Design**
- **Development**
- **Testing**
- **Deployment**
- **Maintenance**

### Introduction to design thinking
#### Design Thinking
Design thinking is a human-centered approach to innovation that draws from the designer's toolkit to integrate the needs of people, the possibilities of technology, and the requirements for business success. So design thinking is a methodology for creative problem solving. It's a way of solving problems that focuses on the user and the user's needs, and it's a way of solving problems that focuses on the user's needs.

#### GDD or Game Design Document
A game design document is a highly descriptive living design document of the design for a video game. A GDD is created and edited by the development team and it is primarily used in the video game industry to organize efforts within a development team.

